{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, cast\n",
    "import os\n",
    "import random\n",
    "from utils import *\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find VideoReorder.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjianghui\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jianghui/VideoReorder/wandb/run-20230220_135657-3es5c5s5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jianghui/VideoReorder/runs/3es5c5s5' target=\"_blank\">iconic-snowball-3</a></strong> to <a href='https://wandb.ai/jianghui/VideoReorder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jianghui/VideoReorder' target=\"_blank\">https://wandb.ai/jianghui/VideoReorder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jianghui/VideoReorder/runs/3es5c5s5' target=\"_blank\">https://wandb.ai/jianghui/VideoReorder/runs/3es5c5s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jianghui/VideoReorder/runs/3es5c5s5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f41f6a5fb50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'VideoReorder'\n",
    "wandb.init(name = 'shot only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jianghui/dataset/VideoReorder-MovieNet'\n",
    "split = 'train'\n",
    "train_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "\n",
    "split = 'val'\n",
    "val_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net.to(device)\n",
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6640595197677612 train score =  0.5821244804237062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:01<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6678372621536255 val score =  0.5786574074074073\n",
      "epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6498633027076721 train score =  0.6152202333065171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 35.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6653242111206055 val score =  0.5896759259259258\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6347200274467468 train score =  0.6364820075757577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6696799397468567 val score =  0.5860648148148148\n",
      "epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 31.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6037259101867676 train score =  0.6707101434700993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:01<00:00, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6942498683929443 val score =  0.5700462962962963\n",
      "epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:28<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.5295026898384094 train score =  0.7323061226200055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 37.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.7622363567352295 val score =  0.558101851851852\n",
      "epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:27<00:00, 32.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.416706919670105 train score =  0.8078908554572267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:01<00:00, 38.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.9020805954933167 val score =  0.5681944444444444\n",
      "epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:27<00:00, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.30437973141670227 train score =  0.8693108490882279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.0730971097946167 val score =  0.5601851851851852\n",
      "epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:28<00:00, 32.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.20832668244838715 train score =  0.9149309047331718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 35.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.265468955039978 val score =  0.55125\n",
      "epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:28<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.14660795032978058 train score =  0.942421309332261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.4500564336776733 val score =  0.5508333333333334\n",
      "epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.10729944705963135 train score =  0.9590833668543826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 35.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.668874979019165 val score =  0.5504166666666668\n",
      "epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.08331193774938583 train score =  0.9683760307723256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.8411871194839478 val score =  0.5503240740740741\n",
      "epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.0772649422287941 train score =  0.9709917203003499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 36.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  1.9625160694122314 val score =  0.5523148148148148\n",
      "epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.057565171271562576 train score =  0.9797490949316173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.1785905361175537 val score =  0.5646759259259259\n",
      "epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.05875478312373161 train score =  0.9785329092920351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.2507638931274414 val score =  0.5668055555555556\n",
      "epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.0482814684510231 train score =  0.9823071701528574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.269176721572876 val score =  0.5551388888888891\n",
      "epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:28<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.05411630868911743 train score =  0.9806489256503113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.4173309803009033 val score =  0.5505555555555557\n",
      "epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:27<00:00, 32.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.04856187850236893 train score =  0.9834772643470119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 37.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.475212574005127 val score =  0.5555092592592591\n",
      "epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:28<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.033718179911375046 train score =  0.9887075958702092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.6183581352233887 val score =  0.5514351851851852\n",
      "epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.046350374817848206 train score =  0.9832258564628602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.5759100914001465 val score =  0.5513425925925923\n",
      "epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.0389455109834671 train score =  0.9863569321533946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.7424590587615967 val score =  0.5445833333333332\n",
      "epoch 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.03914128243923187 train score =  0.9870671594261223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.7988979816436768 val score =  0.5519907407407407\n",
      "epoch 21:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.03305542469024658 train score =  0.9882990580584635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 33.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.6030690670013428 val score =  0.5570833333333334\n",
      "epoch 22:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:29<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.030483713373541832 train score =  0.9897750318450024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 34.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.7652666568756104 val score =  0.5519444444444442\n",
      "epoch 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.034723252058029175 train score =  0.9883158185840734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.822835683822632 val score =  0.5432870370370368\n",
      "epoch 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 904/904 [00:30<00:00, 29.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.032354604452848434 train score =  0.988776733038351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:02<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  2.5385184288024902 val score =  0.5625925925925925\n",
      "epoch 25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 900/904 [00:30<00:00, 29.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m features, gt \u001b[39m=\u001b[39m shot_data\n\u001b[1;32m     24\u001b[0m \u001b[39m# process model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m optim\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(gt) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     28\u001b[0m     output \u001b[39m=\u001b[39m net(features\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/miniconda3/envs/VU_ipy/lib/python3.10/site-packages/torch/optim/optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    277\u001b[0m     p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m foreach \u001b[39mor\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mis_sparse):\n\u001b[0;32m--> 279\u001b[0m     p\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mzero_()\n\u001b[1;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     per_device_and_dtype_grads[p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdevice][p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdtype]\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mgrad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epoch = 40\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func.to(device)\n",
    "pred_func = ClipPairWisePred()\n",
    "pred_func.to(device)\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(f'epoch {e}:')\n",
    "\n",
    "    # train\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(train_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "\n",
    "            # process model\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            if len(gt) == 2:\n",
    "                output = net(features.reshape(-1).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "            elif len(gt) == 3:\n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(3):\n",
    "                    for second_frame in range(first_frame + 1, 3):\n",
    "                        output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                        GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / 3)\n",
    "                score_batch_list.append(score_shot / 3)\n",
    "                \n",
    "            else:\n",
    "                assert False, 'shot frame is neither 2 nor 3'\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "        loss_step.backward()\n",
    "        optim.step()\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        wandb.log({'train loss':loss_step.item(), 'train score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('train loss = ', loss_epoch.item(), 'train score = ', score_epoch)  \n",
    "\n",
    "    # val\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(val_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "            \n",
    "            if len(gt) == 2:\n",
    "                output = net(features.reshape(-1).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "            elif len(gt) == 3:\n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(3):\n",
    "                    for second_frame in range(first_frame + 1, 3):\n",
    "                        output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                        GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / 3)\n",
    "                score_batch_list.append(score_shot / 3)\n",
    "                \n",
    "            else:\n",
    "                assert False, 'shot frame is neither 2 nor 3'\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        wandb.log({'val loss':loss_step.item(), 'val score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test_in_domain'\n",
    "test_in_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "test_in_dataloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "\n",
    "split = 'test_out_domain'\n",
    "test_out_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "test_out_dataloader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "loss_epoch_list = []\n",
    "score_epoch_list = []\n",
    "for batch_data in tqdm(val_dataloader):\n",
    "    loss_batch_list = []\n",
    "    score_batch_list = []\n",
    "\n",
    "    for shot_data in batch_data: #clip data\n",
    "        # read input data\n",
    "        features, gt = shot_data\n",
    "        \n",
    "        if len(gt) == 2:\n",
    "            output = net(features.reshape(-1).unsqueeze(0).to(device))\n",
    "            loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "            PRED = get_order_index(output.reshape(-1).cpu())\n",
    "            GT = gt\n",
    "            score_shot = int(PRED == gt)\n",
    "            # print(PRED, GT)\n",
    "            loss_batch_list.append(loss_shot)\n",
    "            score_batch_list.append(score_shot)\n",
    "        elif len(gt) == 3:\n",
    "            loss_shot = 0\n",
    "            score_shot = 0\n",
    "            for first_frame in range(3):\n",
    "                for second_frame in range(first_frame + 1, 3):\n",
    "                    output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                    loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                    PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                    GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                    # print(PRED, GT)\n",
    "                    score_shot += int(PRED == GT)\n",
    "                    # print(score_shot)\n",
    "            loss_batch_list.append(loss_shot / 3)\n",
    "            score_batch_list.append(score_shot / 3)\n",
    "            \n",
    "        else:\n",
    "            assert False, 'shot frame is neither 2 nor 3'\n",
    "        \n",
    "    # calcuclate avearge batch\n",
    "    score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "    loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "    # caculate avearge score\n",
    "    score_epoch_list.append(score_step)\n",
    "    loss_epoch_list.append(loss_step)\n",
    "    wandb.log({'val loss':loss_step, 'val score':score_step})\n",
    "\n",
    "score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VU_ipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccc6d80109d080f1019495c65bf46629c28f35c0a7d27f040aac1d408f9814c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
