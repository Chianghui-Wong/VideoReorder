{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, cast\n",
    "import os\n",
    "import random\n",
    "from utils import *\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import time\n",
    "import wandb\n",
    "from scipy.special import comb, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# wandb.init(\n",
    "#     project = 'VideoReorder',\n",
    "#     name = 'shot to scene' + timestamp\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jianghui/dataset/VideoReorder-MovieNet'\n",
    "split = 'train'\n",
    "train_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='scene')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "split = 'val'\n",
    "val_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='scene')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024,2)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "net.apply(init_weights)\n",
    "net.to(device)\n",
    "# wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [01:24<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6926583647727966 train score =  0.5158291788778353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:04<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6922639608383179 val score =  0.5266525731430707\n",
      "save epoch  0\n",
      "epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [01:26<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6875216960906982 train score =  0.54557308038177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:04<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6917257308959961 val score =  0.5186389686107324\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [01:25<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6741238832473755 train score =  0.5793670129494234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:04<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6984415054321289 val score =  0.5291834089829894\n",
      "save epoch  2\n",
      "epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [01:25<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6405658721923828 train score =  0.6246577581812285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:04<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.7013086676597595 val score =  0.53235460546494\n",
      "save epoch  3\n",
      "epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [01:26<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.5805218815803528 train score =  0.6827074808695648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:04<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.7339944839477539 val score =  0.5351637765170116\n",
      "save epoch  4\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epoch = 5\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func.to(device)\n",
    "pred_func = ClipPairWisePred()\n",
    "pred_func.to(device)\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for e in range(epoch):\n",
    "    print(f'epoch {e}:')\n",
    "\n",
    "    # train\n",
    "    net.train()\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(train_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for scene_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = scene_data\n",
    "\n",
    "            # get average feature\n",
    "            for i in range(len(features)):\n",
    "                features[i] = torch.mean(features[i], dim = 0)\n",
    "            features = torch.stack(features, dim=0)\n",
    "\n",
    "            # process model\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            N = len(gt)\n",
    "            loss_scene = 0\n",
    "            score_scene = 0\n",
    "            for first_frame in range(N):\n",
    "                for second_frame in range(first_frame + 1, N):\n",
    "                    output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                    loss_scene += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                    PRED = get_order_list(output.reshape(-1).cpu())\n",
    "                    GT = get_order_list([gt[first_frame], gt[second_frame]])\n",
    "                    # print(PRED, GT)\n",
    "                    score_scene += int(PRED == GT)\n",
    "                    # print(score_scene)\n",
    "            loss_batch_list.append(loss_scene / comb(N, 2))\n",
    "            score_batch_list.append(score_scene / comb(N, 2))\n",
    "                \n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "        loss_step.backward()\n",
    "        optim.step()\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        # wandb.log({'train loss':loss_step.item(), 'train score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('train loss = ', loss_epoch.item(), 'train score = ', score_epoch)  \n",
    "\n",
    "    # val\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_epoch_list = []\n",
    "        score_epoch_list = []\n",
    "        for batch_data in tqdm(val_dataloader):\n",
    "            loss_batch_list = []\n",
    "            score_batch_list = []\n",
    "\n",
    "            for scene_data in batch_data: #clip data\n",
    "                # read input data\n",
    "                features, gt = scene_data\n",
    "                \n",
    "                # get average feature\n",
    "                for i in range(len(features)):\n",
    "                    features[i] = torch.mean(features[i], dim = 0)\n",
    "                features = torch.stack(features, dim=0)\n",
    "\n",
    "                N = len(gt)\n",
    "                loss_scene = 0\n",
    "                score_scene = 0\n",
    "                for first_frame in range(N):\n",
    "                    for second_frame in range(first_frame + 1, N):\n",
    "                        output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_scene += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_list(output.reshape(-1).cpu())\n",
    "                        GT = get_order_list([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_scene += int(PRED == GT)\n",
    "                        # print(score_scene)\n",
    "                loss_batch_list.append(loss_scene / comb(N, 2))\n",
    "                score_batch_list.append(score_scene / comb(N, 2))\n",
    "                \n",
    "            # calcuclate avearge batch\n",
    "            score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "            loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "            # caculate avearge score\n",
    "            score_epoch_list.append(score_step)\n",
    "            loss_epoch_list.append(loss_step)\n",
    "            # wandb.log({'val loss':loss_step.item(), 'val score':score_step})\n",
    "\n",
    "        score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "        loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "        print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)\n",
    "        if score_epoch >= best_val_acc: \n",
    "            best_val_acc = score_epoch\n",
    "            torch.save(net.state_dict(), Path('./checkpoint', f'shot_to_scene_best_{timestamp}.pth'))\n",
    "            print(\"save epoch \",e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5afd70db720be3800db2de41727453e3061ee2e6ab9dd2afe0b69a2412604e4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
