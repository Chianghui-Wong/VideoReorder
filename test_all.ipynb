{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, cast\n",
    "import os\n",
    "import random\n",
    "from utils import *\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import time\n",
    "from scipy.special import comb, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.init(\n",
    "#     project = 'VideoReorder',\n",
    "#     name = 'shot only'\n",
    "#     )\n",
    "timestamp = time.strftime('%Y-%m-%d', time.localtime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jianghui/dataset/VideoReorder-MovieNet'\n",
    "split = 'train'\n",
    "train_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "\n",
    "split = 'val'\n",
    "val_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net.to(device)\n",
    "# wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [04:58<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6931282877922058 train score =  0.5040786786995005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6928536295890808 val score =  0.5107599981706323\n",
      "save epoch  0\n",
      "epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [04:54<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6926515102386475 train score =  0.5121648323330041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6924921274185181 val score =  0.5146516291602038\n",
      "save epoch  1\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [05:09<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6914034485816956 train score =  0.5234265681512226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6931868195533752 val score =  0.5079427487786092\n",
      "epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [04:57<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6859269738197327 train score =  0.5466020443811009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.6984450221061707 val score =  0.5062540407960507\n",
      "epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [04:48<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss =  0.6690531969070435 train score =  0.5866740166324739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss =  0.714319109916687 val score =  0.4978416102227202\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epoch = 5\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func.to(device)\n",
    "pred_func = ClipPairWisePred()\n",
    "pred_func.to(device)\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for e in range(epoch):\n",
    "    print(f'epoch {e}:')\n",
    "\n",
    "    # train\n",
    "    net.train()\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(train_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for all_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, img_id, _, _ = all_data\n",
    "            gt = get_order_index(img_id)\n",
    "            N = len(gt)\n",
    "\n",
    "            # process model\n",
    "            optim.zero_grad()\n",
    "\n",
    "            loss_shot = 0\n",
    "            score_shot = 0\n",
    "            for first_frame in range(N):\n",
    "                for second_frame in range(first_frame + 1, N):\n",
    "                    output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                    loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                    PRED = get_order_list(output.reshape(-1).cpu())\n",
    "                    GT = get_order_list([gt[first_frame], gt[second_frame]])\n",
    "                    # print(PRED, GT)\n",
    "                    score_shot += int(PRED == GT)\n",
    "                    # print(score_shot)\n",
    "            loss_batch_list.append(loss_shot / comb(N, 2))\n",
    "            score_batch_list.append(score_shot / comb(N, 2))\n",
    "                \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "        loss_step.backward()\n",
    "        optim.step()\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        # wandb.log({'train loss':loss_step.item(), 'train score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('train loss = ', loss_epoch.item(), 'train score = ', score_epoch)  \n",
    "\n",
    "    # val\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_epoch_list = []\n",
    "        score_epoch_list = []\n",
    "        for batch_data in tqdm(val_dataloader):\n",
    "            loss_batch_list = []\n",
    "            score_batch_list = []\n",
    "\n",
    "            for all_data in batch_data: #clip data\n",
    "                features, img_id, _, _ = all_data\n",
    "                gt = get_order_index(img_id)\n",
    "                N = len(gt)\n",
    "                \n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(N):\n",
    "                    for second_frame in range(first_frame + 1, N):\n",
    "                        output = net(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_list(output.reshape(-1).cpu())\n",
    "                        GT = get_order_list([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / comb(N, 2))\n",
    "                score_batch_list.append(score_shot / comb(N, 2))\n",
    "                \n",
    "            # calcuclate avearge batch\n",
    "            score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "            loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "            # caculate avearge score\n",
    "            score_epoch_list.append(score_step)\n",
    "            loss_epoch_list.append(loss_step)\n",
    "            # wandb.log({'val loss':loss_step.item(), 'val score':score_step})\n",
    "\n",
    "        score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "        loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "        print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)\n",
    "        if score_epoch >= best_val_acc: \n",
    "            best_val_acc = score_epoch\n",
    "            torch.save(net.state_dict(), Path('./checkpoint', f'all_best_{timestamp}.pth'))\n",
    "            print(\"save epoch \",e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5afd70db720be3800db2de41727453e3061ee2e6ab9dd2afe0b69a2412604e4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
