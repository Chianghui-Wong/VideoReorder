{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, cast\n",
    "import os\n",
    "import random\n",
    "from utils import *\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoProcessor, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import time\n",
    "from scipy.special import comb, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "timestamp = time.strftime('%Y-%m-%d', time.localtime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjianghui\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jianghui/VideoReorder/wandb/run-20230227_014338-56095uwb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jianghui/VideoReorder/runs/56095uwb' target=\"_blank\">frame to shot</a></strong> to <a href='https://wandb.ai/jianghui/VideoReorder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jianghui/VideoReorder' target=\"_blank\">https://wandb.ai/jianghui/VideoReorder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jianghui/VideoReorder/runs/56095uwb' target=\"_blank\">https://wandb.ai/jianghui/VideoReorder/runs/56095uwb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jianghui/VideoReorder/runs/56095uwb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff90d53c880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = 'VideoReorder',\n",
    "    name = 'frame to shot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jianghui/dataset/VideoReorder-MovieNet'\n",
    "split = 'train'\n",
    "train_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='frame')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "\n",
    "split = 'val'\n",
    "val_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='frame')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net.to(device)\n",
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n",
      "train loss =  0.6933961510658264 train score =  0.4965234116479153\n",
      "val loss =  0.6932701468467712 val score =  0.5\n",
      "save epoch  0\n",
      "epoch 1:\n",
      "train loss =  0.6932544112205505 train score =  0.49962979814692254\n",
      "val loss =  0.69318026304245 val score =  0.5\n",
      "save epoch  1\n",
      "epoch 2:\n",
      "train loss =  0.6930450797080994 train score =  0.5060018199867637\n",
      "val loss =  0.6931925415992737 val score =  0.5003676470588235\n",
      "save epoch  2\n",
      "epoch 3:\n",
      "train loss =  0.691364049911499 train score =  0.5248221376571807\n",
      "val loss =  0.6956872344017029 val score =  0.49754901960784315\n",
      "epoch 4:\n",
      "train loss =  0.6817213296890259 train score =  0.5543328093977498\n",
      "val loss =  0.7024040818214417 val score =  0.489828431372549\n",
      "epoch 5:\n",
      "train loss =  0.6470097899436951 train score =  0.6088641628060887\n",
      "val loss =  0.7247036695480347 val score =  0.4883578431372549\n",
      "epoch 6:\n",
      "train loss =  0.575337827205658 train score =  0.6798188285903375\n",
      "val loss =  0.8016448616981506 val score =  0.49436274509803924\n",
      "epoch 7:\n",
      "train loss =  0.48053890466690063 train score =  0.7493071641297154\n",
      "val loss =  0.9050248265266418 val score =  0.4936274509803922\n",
      "epoch 8:\n",
      "train loss =  0.38692426681518555 train score =  0.8074557412309729\n",
      "val loss =  1.1185698509216309 val score =  0.49387254901960786\n",
      "epoch 9:\n",
      "train loss =  0.3116704225540161 train score =  0.8493940271343482\n",
      "val loss =  1.3025399446487427 val score =  0.49240196078431375\n",
      "epoch 10:\n",
      "train loss =  0.2588599622249603 train score =  0.8768923726009266\n",
      "val loss =  1.487408995628357 val score =  0.49019607843137253\n",
      "epoch 11:\n",
      "train loss =  0.21684938669204712 train score =  0.8992223692918596\n",
      "val loss =  1.6834256649017334 val score =  0.4928921568627451\n",
      "epoch 12:\n",
      "train loss =  0.19218944013118744 train score =  0.9110522832561218\n",
      "val loss =  1.8356566429138184 val score =  0.48970588235294116\n",
      "epoch 13:\n",
      "train loss =  0.17090657353401184 train score =  0.9227270847121112\n",
      "val loss =  1.9633985757827759 val score =  0.49583333333333335\n",
      "epoch 14:\n",
      "train loss =  0.15677164494991302 train score =  0.9296616479152879\n",
      "val loss =  1.979053020477295 val score =  0.4991421568627451\n",
      "epoch 15:\n",
      "train loss =  0.14297620952129364 train score =  0.935704831237591\n",
      "val loss =  2.159729242324829 val score =  0.4928921568627451\n",
      "epoch 16:\n",
      "train loss =  0.13674834370613098 train score =  0.938699536730642\n",
      "val loss =  2.2299840450286865 val score =  0.5026960784313725\n",
      "save epoch  16\n",
      "epoch 17:\n",
      "train loss =  0.1257980465888977 train score =  0.9442112011912641\n",
      "val loss =  2.2349612712860107 val score =  0.49926470588235294\n",
      "epoch 18:\n",
      "train loss =  0.11744479089975357 train score =  0.947737425545996\n",
      "val loss =  2.2513504028320312 val score =  0.4954656862745098\n",
      "epoch 19:\n",
      "train loss =  0.11231407523155212 train score =  0.9504198378557246\n",
      "val loss =  2.5751633644104004 val score =  0.49240196078431375\n",
      "epoch 20:\n",
      "train loss =  0.10683266073465347 train score =  0.9529492058239576\n",
      "val loss =  2.4631686210632324 val score =  0.49522058823529413\n",
      "epoch 21:\n",
      "train loss =  0.09982854872941971 train score =  0.9561072964923891\n",
      "val loss =  2.499135971069336 val score =  0.49387254901960786\n",
      "epoch 22:\n",
      "train loss =  0.09899873286485672 train score =  0.9561052283256122\n",
      "val loss =  2.4387176036834717 val score =  0.49693627450980393\n",
      "epoch 23:\n",
      "train loss =  0.09305227547883987 train score =  0.9589923891462607\n",
      "val loss =  2.6170527935028076 val score =  0.5009803921568627\n",
      "epoch 24:\n",
      "train loss =  0.08954403549432755 train score =  0.9607813534083388\n",
      "val loss =  2.6206512451171875 val score =  0.5035539215686274\n",
      "save epoch  24\n",
      "epoch 25:\n",
      "train loss =  0.08514495939016342 train score =  0.96236350099272\n",
      "val loss =  2.6728620529174805 val score =  0.49816176470588236\n",
      "epoch 26:\n",
      "train loss =  0.08364661782979965 train score =  0.962828838517538\n",
      "val loss =  2.5849626064300537 val score =  0.4931372549019608\n",
      "epoch 27:\n",
      "train loss =  0.08012578636407852 train score =  0.965755294506949\n",
      "val loss =  2.5990524291992188 val score =  0.4933823529411765\n",
      "epoch 28:\n",
      "train loss =  0.07615119963884354 train score =  0.9661751323626737\n",
      "val loss =  2.6600868701934814 val score =  0.4993872549019608\n",
      "epoch 29:\n",
      "train loss =  0.07393594086170197 train score =  0.9677200529450695\n",
      "val loss =  2.708866834640503 val score =  0.4979166666666667\n",
      "epoch 30:\n",
      "train loss =  0.07084821164608002 train score =  0.9691326108537393\n",
      "val loss =  2.8093740940093994 val score =  0.4985294117647059\n",
      "epoch 31:\n",
      "train loss =  0.07033593207597733 train score =  0.9701563534083388\n",
      "val loss =  2.647895336151123 val score =  0.5002450980392157\n",
      "epoch 32:\n",
      "train loss =  0.06860457360744476 train score =  0.9709298477829252\n",
      "val loss =  2.6952710151672363 val score =  0.49963235294117647\n",
      "epoch 33:\n",
      "train loss =  0.06557324528694153 train score =  0.9717591826604898\n",
      "val loss =  2.8042380809783936 val score =  0.4985294117647059\n",
      "epoch 34:\n",
      "train loss =  0.06471659243106842 train score =  0.9726319490403705\n",
      "val loss =  2.8744542598724365 val score =  0.5030637254901961\n",
      "epoch 35:\n",
      "train loss =  0.06105519458651543 train score =  0.9738066677696889\n",
      "val loss =  3.012430191040039 val score =  0.4954656862745098\n",
      "epoch 36:\n",
      "train loss =  0.06046973913908005 train score =  0.9747683653209794\n",
      "val loss =  2.9832115173339844 val score =  0.5020833333333333\n",
      "epoch 37:\n",
      "train loss =  0.058861564844846725 train score =  0.976065105890139\n",
      "val loss =  2.8288052082061768 val score =  0.4946078431372549\n",
      "epoch 38:\n",
      "train loss =  0.05638511851429939 train score =  0.9763443084050297\n",
      "val loss =  2.9714174270629883 val score =  0.5012254901960784\n",
      "epoch 39:\n",
      "train loss =  0.056110747158527374 train score =  0.9766131700860357\n",
      "val loss =  2.9530534744262695 val score =  0.49031862745098037\n",
      "epoch 40:\n",
      "train loss =  0.05338011682033539 train score =  0.9782408173395103\n",
      "val loss =  3.070549964904785 val score =  0.49779411764705883\n",
      "epoch 41:\n",
      "train loss =  0.05358384922146797 train score =  0.9779471376571807\n",
      "val loss =  3.1915996074676514 val score =  0.5036764705882353\n",
      "save epoch  41\n",
      "epoch 42:\n",
      "train loss =  0.052089232951402664 train score =  0.9789357213765718\n",
      "val loss =  2.9524686336517334 val score =  0.4925245098039216\n",
      "epoch 43:\n",
      "train loss =  0.050234489142894745 train score =  0.9800628722700199\n",
      "val loss =  3.0010411739349365 val score =  0.4936274509803922\n",
      "epoch 44:\n",
      "train loss =  0.0488821305334568 train score =  0.9801973031105228\n",
      "val loss =  3.0207817554473877 val score =  0.49816176470588236\n",
      "epoch 45:\n",
      "train loss =  0.04953750595450401 train score =  0.9805530277961614\n",
      "val loss =  3.0399351119995117 val score =  0.4931372549019608\n",
      "epoch 46:\n",
      "train loss =  0.0470256544649601 train score =  0.9818311548643283\n",
      "val loss =  2.9500749111175537 val score =  0.4928921568627451\n",
      "epoch 47:\n",
      "train loss =  0.04398800805211067 train score =  0.9822241065519524\n",
      "val loss =  3.098435163497925 val score =  0.49901960784313726\n",
      "epoch 48:\n",
      "train loss =  0.04449925199151039 train score =  0.9820896757114493\n",
      "val loss =  3.0844709873199463 val score =  0.49779411764705883\n",
      "epoch 49:\n",
      "train loss =  0.044204968959093094 train score =  0.9827514890800794\n",
      "val loss =  2.963212013244629 val score =  0.4933823529411765\n",
      "epoch 50:\n",
      "train loss =  0.041363783180713654 train score =  0.983444324950364\n",
      "val loss =  3.0901975631713867 val score =  0.4917892156862745\n",
      "epoch 51:\n",
      "train loss =  0.04170863330364227 train score =  0.9837545499669094\n",
      "val loss =  3.112788438796997 val score =  0.4988970588235294\n",
      "epoch 52:\n",
      "train loss =  0.04077041521668434 train score =  0.9844990900066182\n",
      "val loss =  3.2121713161468506 val score =  0.4927696078431373\n",
      "epoch 53:\n",
      "train loss =  0.03953873738646507 train score =  0.9842302283256121\n",
      "val loss =  3.0735666751861572 val score =  0.49203431372549017\n",
      "epoch 54:\n",
      "train loss =  0.03984358534216881 train score =  0.9856055592322965\n",
      "val loss =  3.033886671066284 val score =  0.4974264705882353\n",
      "epoch 55:\n",
      "train loss =  0.03725047409534454 train score =  0.9858123759099934\n",
      "val loss =  3.1701953411102295 val score =  0.4965686274509804\n",
      "epoch 56:\n",
      "train loss =  0.03914567828178406 train score =  0.9855952183984117\n",
      "val loss =  3.309145927429199 val score =  0.4974264705882353\n",
      "epoch 57:\n",
      "train loss =  0.035007476806640625 train score =  0.9863955989410985\n",
      "val loss =  3.371082067489624 val score =  0.4939950980392157\n",
      "epoch 58:\n",
      "train loss =  0.03593679517507553 train score =  0.9858578755790867\n",
      "val loss =  3.3544342517852783 val score =  0.4912990196078431\n",
      "epoch 59:\n",
      "train loss =  0.03684287518262863 train score =  0.9861743050959629\n",
      "val loss =  3.4730868339538574 val score =  0.4948529411764706\n",
      "epoch 60:\n",
      "train loss =  0.03320124000310898 train score =  0.9875806585043018\n",
      "val loss =  3.275674819946289 val score =  0.49497549019607845\n",
      "epoch 61:\n",
      "train loss =  0.0344439372420311 train score =  0.9873945234943746\n",
      "val loss =  3.2150228023529053 val score =  0.4933823529411765\n",
      "epoch 62:\n",
      "train loss =  0.03348837420344353 train score =  0.9876737260092654\n",
      "val loss =  3.4126994609832764 val score =  0.49730392156862746\n",
      "epoch 63:\n",
      "train loss =  0.03411886468529701 train score =  0.9881328590337525\n",
      "val loss =  3.2538645267486572 val score =  0.5002450980392157\n",
      "epoch 64:\n",
      "train loss =  0.03212742507457733 train score =  0.9880046326935804\n",
      "val loss =  3.2352426052093506 val score =  0.49816176470588236\n",
      "epoch 65:\n",
      "train loss =  0.030913811177015305 train score =  0.9887491727332892\n",
      "val loss =  3.4664628505706787 val score =  0.49436274509803924\n",
      "epoch 66:\n",
      "train loss =  0.032128166407346725 train score =  0.9886292190602249\n",
      "val loss =  3.323775291442871 val score =  0.49019607843137253\n",
      "epoch 67:\n",
      "train loss =  0.03108196146786213 train score =  0.9891007610853739\n",
      "val loss =  3.3658294677734375 val score =  0.5020833333333333\n",
      "epoch 68:\n",
      "train loss =  0.02954467572271824 train score =  0.989094556585043\n",
      "val loss =  3.378013849258423 val score =  0.49754901960784315\n",
      "epoch 69:\n",
      "train loss =  0.030746707692742348 train score =  0.988625082726671\n",
      "val loss =  3.287421941757202 val score =  0.5034313725490196\n",
      "epoch 70:\n",
      "train loss =  0.02894938550889492 train score =  0.9893489410986102\n",
      "val loss =  3.290971279144287 val score =  0.4993872549019608\n",
      "epoch 71:\n",
      "train loss =  0.02770683728158474 train score =  0.9902320483123759\n",
      "val loss =  3.5277209281921387 val score =  0.49840686274509804\n",
      "epoch 72:\n",
      "train loss =  0.02972048707306385 train score =  0.9893179185969556\n",
      "val loss =  3.2171335220336914 val score =  0.4936274509803922\n",
      "epoch 73:\n",
      "train loss =  0.027725491672754288 train score =  0.9901762078093977\n",
      "val loss =  3.354735851287842 val score =  0.4950980392156863\n",
      "epoch 74:\n",
      "train loss =  0.026211069896817207 train score =  0.9903313203176705\n",
      "val loss =  3.540745735168457 val score =  0.5003676470588235\n",
      "epoch 75:\n",
      "train loss =  0.027737146243453026 train score =  0.990362342819325\n",
      "val loss =  3.415414810180664 val score =  0.4944852941176471\n",
      "epoch 76:\n",
      "train loss =  0.02652743272483349 train score =  0.9904967736598279\n",
      "val loss =  3.3933470249176025 val score =  0.4968137254901961\n",
      "epoch 77:\n",
      "train loss =  0.026672376319766045 train score =  0.9905691594970218\n",
      "val loss =  3.3248038291931152 val score =  0.4962009803921569\n",
      "epoch 78:\n",
      "train loss =  0.026547785848379135 train score =  0.9903706154864329\n",
      "val loss =  3.4199204444885254 val score =  0.49926470588235294\n",
      "epoch 79:\n",
      "train loss =  0.025903500616550446 train score =  0.9911730641958967\n",
      "val loss =  3.4169559478759766 val score =  0.4965686274509804\n",
      "epoch 80:\n",
      "train loss =  0.025911372154951096 train score =  0.9910655195234944\n",
      "val loss =  3.6303322315216064 val score =  0.5019607843137255\n",
      "epoch 81:\n",
      "train loss =  0.025249458849430084 train score =  0.9910448378557247\n",
      "val loss =  3.2517168521881104 val score =  0.5019607843137255\n",
      "epoch 82:\n",
      "train loss =  0.025347484275698662 train score =  0.991079996690933\n",
      "val loss =  3.320789098739624 val score =  0.4928921568627451\n",
      "epoch 83:\n",
      "train loss =  0.02332443557679653 train score =  0.9916859695565851\n",
      "val loss =  3.4808523654937744 val score =  0.4950980392156863\n",
      "epoch 84:\n",
      "train loss =  0.0241599902510643 train score =  0.9917480145598941\n",
      "val loss =  3.7597038745880127 val score =  0.4980392156862745\n",
      "epoch 85:\n",
      "train loss =  0.025506049394607544 train score =  0.9910655195234944\n",
      "val loss =  3.3921453952789307 val score =  0.49754901960784315\n",
      "epoch 86:\n",
      "train loss =  0.022010041400790215 train score =  0.9925132362673726\n",
      "val loss =  3.581738233566284 val score =  0.4904411764705882\n",
      "epoch 87:\n",
      "train loss =  0.02412521280348301 train score =  0.9918348775645267\n",
      "val loss =  3.537775993347168 val score =  0.49730392156862746\n",
      "epoch 88:\n",
      "train loss =  0.02369098737835884 train score =  0.9915825612177366\n",
      "val loss =  3.717085361480713 val score =  0.4974264705882353\n",
      "epoch 89:\n",
      "train loss =  0.022289743646979332 train score =  0.9926476671078756\n",
      "val loss =  3.5317893028259277 val score =  0.5026960784313725\n",
      "epoch 90:\n",
      "train loss =  0.02264593541622162 train score =  0.9922340337524818\n",
      "val loss =  3.641601085662842 val score =  0.5019607843137255\n",
      "epoch 91:\n",
      "train loss =  0.023253103718161583 train score =  0.9920272170747849\n",
      "val loss =  3.3979830741882324 val score =  0.4979166666666667\n",
      "epoch 92:\n",
      "train loss =  0.02140127494931221 train score =  0.9923271012574454\n",
      "val loss =  3.3931972980499268 val score =  0.5004901960784314\n",
      "epoch 93:\n",
      "train loss =  0.020157303661108017 train score =  0.992823461283918\n",
      "val loss =  3.5503549575805664 val score =  0.49411764705882355\n",
      "epoch 94:\n",
      "train loss =  0.021193042397499084 train score =  0.9926373262739907\n",
      "val loss =  3.596754789352417 val score =  0.4957107843137255\n",
      "epoch 95:\n",
      "train loss =  0.021770194172859192 train score =  0.992823461283918\n",
      "val loss =  3.6229934692382812 val score =  0.4957107843137255\n",
      "epoch 96:\n",
      "train loss =  0.021497195586562157 train score =  0.9925959629384513\n",
      "val loss =  3.634371519088745 val score =  0.4963235294117647\n",
      "epoch 97:\n",
      "train loss =  0.020342150703072548 train score =  0.99301993712773\n",
      "val loss =  3.547642230987549 val score =  0.49166666666666664\n",
      "epoch 98:\n",
      "train loss =  0.021737387403845787 train score =  0.9928131204500331\n",
      "val loss =  3.6984341144561768 val score =  0.49497549019607845\n",
      "epoch 99:\n",
      "train loss =  0.020704463124275208 train score =  0.9927924387822634\n",
      "val loss =  3.7458183765411377 val score =  0.4965686274509804\n",
      "epoch 100:\n",
      "train loss =  0.02042006514966488 train score =  0.9930757776307081\n",
      "val loss =  3.731635093688965 val score =  0.4993872549019608\n",
      "epoch 101:\n",
      "train loss =  0.020474493503570557 train score =  0.9928441429516877\n",
      "val loss =  3.609943151473999 val score =  0.49987745098039216\n",
      "epoch 102:\n",
      "train loss =  0.01962870918214321 train score =  0.9932991396426207\n",
      "val loss =  3.6168336868286133 val score =  0.49350490196078434\n",
      "epoch 103:\n",
      "train loss =  0.01761912927031517 train score =  0.9934956154864328\n",
      "val loss =  3.8710970878601074 val score =  0.49583333333333335\n",
      "epoch 104:\n",
      "train loss =  0.019834542647004128 train score =  0.9931957313037724\n",
      "val loss =  3.7143630981445312 val score =  0.4917892156862745\n",
      "epoch 105:\n",
      "train loss =  0.018732478842139244 train score =  0.993619705493051\n",
      "val loss =  3.715789556503296 val score =  0.49325980392156865\n",
      "epoch 106:\n",
      "train loss =  0.0193033330142498 train score =  0.9933405029781601\n",
      "val loss =  3.741335153579712 val score =  0.4950980392156863\n",
      "epoch 107:\n",
      "train loss =  0.021378153935074806 train score =  0.992823461283918\n",
      "val loss =  3.272427797317505 val score =  0.49117647058823527\n",
      "epoch 108:\n",
      "train loss =  0.019391929730772972 train score =  0.9935266379880874\n",
      "val loss =  3.589804172515869 val score =  0.4933823529411765\n",
      "epoch 109:\n",
      "train loss =  0.01984923705458641 train score =  0.9933715254798147\n",
      "val loss =  3.5679895877838135 val score =  0.4974264705882353\n",
      "epoch 110:\n",
      "train loss =  0.018225878477096558 train score =  0.9938368630046327\n",
      "val loss =  3.5782527923583984 val score =  0.5\n",
      "epoch 111:\n",
      "train loss =  0.018057988956570625 train score =  0.9940229980145598\n",
      "val loss =  3.926018714904785 val score =  0.49583333333333335\n",
      "epoch 112:\n",
      "train loss =  0.019079972058534622 train score =  0.9934480476505625\n",
      "val loss =  3.6025044918060303 val score =  0.5003676470588235\n",
      "epoch 113:\n",
      "train loss =  0.019097471609711647 train score =  0.9937334546657842\n",
      "val loss =  3.6444156169891357 val score =  0.504656862745098\n",
      "save epoch  113\n",
      "epoch 114:\n",
      "train loss =  0.018018340691924095 train score =  0.9941264063534083\n",
      "val loss =  3.685730457305908 val score =  0.49730392156862746\n",
      "epoch 115:\n",
      "train loss =  0.01757064275443554 train score =  0.994147088021178\n",
      "val loss =  3.706270456314087 val score =  0.49840686274509804\n",
      "epoch 116:\n",
      "train loss =  0.01721443049609661 train score =  0.9943849272005294\n",
      "val loss =  3.680504083633423 val score =  0.4980392156862745\n",
      "epoch 117:\n",
      "train loss =  0.01744021102786064 train score =  0.9939030443414957\n",
      "val loss =  3.539783239364624 val score =  0.4965686274509804\n",
      "epoch 118:\n",
      "train loss =  0.01878923363983631 train score =  0.9937437954996691\n",
      "val loss =  3.619419574737549 val score =  0.49669117647058825\n",
      "epoch 119:\n",
      "train loss =  0.01594943180680275 train score =  0.9947778788881535\n",
      "val loss =  3.76464581489563 val score =  0.49754901960784315\n",
      "epoch 120:\n",
      "train loss =  0.018871206790208817 train score =  0.9940643613500992\n",
      "val loss =  3.887643814086914 val score =  0.4933823529411765\n",
      "epoch 121:\n",
      "train loss =  0.017437221482396126 train score =  0.9939712938451357\n",
      "val loss =  3.516900062561035 val score =  0.49644607843137256\n",
      "epoch 122:\n",
      "train loss =  0.016793834045529366 train score =  0.9945917438782264\n",
      "val loss =  3.6260788440704346 val score =  0.4946078431372549\n",
      "epoch 123:\n",
      "train loss =  0.017412731423974037 train score =  0.9944262905360688\n",
      "val loss =  3.6096181869506836 val score =  0.4970588235294118\n",
      "epoch 124:\n",
      "train loss =  0.015857340767979622 train score =  0.9946641297154203\n",
      "val loss =  3.6997506618499756 val score =  0.49779411764705883\n",
      "epoch 125:\n",
      "train loss =  0.017808478325605392 train score =  0.9943022005294507\n",
      "val loss =  3.4998083114624023 val score =  0.4968137254901961\n",
      "epoch 126:\n",
      "train loss =  0.016455339267849922 train score =  0.994612425545996\n",
      "val loss =  3.6895742416381836 val score =  0.5018382352941176\n",
      "epoch 127:\n",
      "train loss =  0.0165561493486166 train score =  0.9946744705493051\n",
      "val loss =  3.4643900394439697 val score =  0.4942401960784314\n",
      "epoch 128:\n",
      "train loss =  0.016742177307605743 train score =  0.9944159497021839\n",
      "val loss =  3.5516631603240967 val score =  0.4954656862745098\n",
      "epoch 129:\n",
      "train loss =  0.01578361727297306 train score =  0.9949019688947717\n",
      "val loss =  3.678691864013672 val score =  0.49436274509803924\n",
      "epoch 130:\n",
      "train loss =  0.015104456804692745 train score =  0.9949019688947717\n",
      "val loss =  3.789879083633423 val score =  0.49583333333333335\n",
      "epoch 131:\n",
      "train loss =  0.017557619139552116 train score =  0.994219473858372\n",
      "val loss =  3.6148900985717773 val score =  0.48909313725490194\n",
      "epoch 132:\n",
      "train loss =  0.01674969121813774 train score =  0.9949743547319656\n",
      "val loss =  3.5912740230560303 val score =  0.49950980392156863\n",
      "epoch 133:\n",
      "train loss =  0.014828759245574474 train score =  0.9952638980807412\n",
      "val loss =  3.764857769012451 val score =  0.49901960784313726\n",
      "epoch 134:\n",
      "train loss =  0.014372036792337894 train score =  0.9951915122435473\n",
      "val loss =  3.840634822845459 val score =  0.4959558823529412\n",
      "epoch 135:\n",
      "train loss =  0.016854993999004364 train score =  0.9945710622104567\n",
      "val loss =  3.5770647525787354 val score =  0.4959558823529412\n",
      "epoch 136:\n",
      "train loss =  0.014477495104074478 train score =  0.9951604897418928\n",
      "val loss =  3.941805124282837 val score =  0.49558823529411766\n",
      "epoch 137:\n",
      "train loss =  0.015812689438462257 train score =  0.9946372435473196\n",
      "val loss =  3.9173035621643066 val score =  0.4925245098039216\n",
      "epoch 138:\n",
      "train loss =  0.014209822751581669 train score =  0.9951604897418928\n",
      "val loss =  3.9053473472595215 val score =  0.4959558823529412\n",
      "epoch 139:\n",
      "train loss =  0.016240540891885757 train score =  0.9946434480476506\n",
      "val loss =  3.669219732284546 val score =  0.49264705882352944\n",
      "epoch 140:\n",
      "train loss =  0.013837547041475773 train score =  0.9955741230972865\n",
      "val loss =  3.8960654735565186 val score =  0.5026960784313725\n",
      "epoch 141:\n",
      "train loss =  0.0157451368868351 train score =  0.9946331072137657\n",
      "val loss =  3.675798177719116 val score =  0.4982843137254902\n",
      "epoch 142:\n",
      "train loss =  0.014467038214206696 train score =  0.9953259430840503\n",
      "val loss =  3.930478811264038 val score =  0.4944852941176471\n",
      "epoch 143:\n",
      "train loss =  0.01592964492738247 train score =  0.994808901389808\n",
      "val loss =  3.5000128746032715 val score =  0.49730392156862746\n",
      "epoch 144:\n",
      "train loss =  0.01456616260111332 train score =  0.9955741230972865\n",
      "val loss =  3.788970947265625 val score =  0.4987745098039216\n",
      "epoch 145:\n",
      "train loss =  0.015203462913632393 train score =  0.9954603739245532\n",
      "val loss =  3.8447694778442383 val score =  0.5018382352941176\n",
      "epoch 146:\n",
      "train loss =  0.014040489681065083 train score =  0.9953776472534746\n",
      "val loss =  3.6514768600463867 val score =  0.503921568627451\n",
      "epoch 147:\n",
      "train loss =  0.013834092766046524 train score =  0.9953362839179352\n",
      "val loss =  3.877763509750366 val score =  0.49950980392156863\n",
      "epoch 148:\n",
      "train loss =  0.015447624959051609 train score =  0.9952225347452018\n",
      "val loss =  3.8621368408203125 val score =  0.49644607843137256\n",
      "epoch 149:\n",
      "train loss =  0.014156562276184559 train score =  0.9954603739245532\n",
      "val loss =  3.9035723209381104 val score =  0.4962009803921569\n",
      "epoch 150:\n",
      "train loss =  0.01469083596020937 train score =  0.9951604897418928\n",
      "val loss =  3.8191003799438477 val score =  0.5\n",
      "epoch 151:\n",
      "train loss =  0.014148810878396034 train score =  0.995543100595632\n",
      "val loss =  4.0975260734558105 val score =  0.4968137254901961\n",
      "epoch 152:\n",
      "train loss =  0.014515132643282413 train score =  0.9953817835870284\n",
      "val loss =  3.924889326095581 val score =  0.5008578431372549\n",
      "epoch 153:\n",
      "train loss =  0.014689849689602852 train score =  0.9951811714096624\n",
      "val loss =  3.760258436203003 val score =  0.5006127450980392\n",
      "epoch 154:\n",
      "train loss =  0.01344169583171606 train score =  0.995749917273329\n",
      "val loss =  3.876387357711792 val score =  0.49558823529411766\n",
      "epoch 155:\n",
      "train loss =  0.013466172851622105 train score =  0.995946393117141\n",
      "val loss =  3.704559087753296 val score =  0.49240196078431375\n",
      "epoch 156:\n",
      "train loss =  0.013795710168778896 train score =  0.9955224189278623\n",
      "val loss =  4.104053974151611 val score =  0.49840686274509804\n",
      "epoch 157:\n",
      "train loss =  0.01419141050428152 train score =  0.9953259430840503\n",
      "val loss =  3.7925429344177246 val score =  0.4933823529411765\n",
      "epoch 158:\n",
      "train loss =  0.014179660938680172 train score =  0.9954603739245532\n",
      "val loss =  3.7037978172302246 val score =  0.49522058823529413\n",
      "epoch 159:\n",
      "train loss =  0.01321121770888567 train score =  0.9958533256121773\n",
      "val loss =  3.7871007919311523 val score =  0.49583333333333335\n",
      "epoch 160:\n",
      "train loss =  0.015298200771212578 train score =  0.9949329913964262\n",
      "val loss =  3.544072389602661 val score =  0.4963235294117647\n",
      "epoch 161:\n",
      "train loss =  0.012849130667746067 train score =  0.9959980972865652\n",
      "val loss =  3.728938341140747 val score =  0.492156862745098\n",
      "epoch 162:\n",
      "train loss =  0.01446387730538845 train score =  0.9957085539377896\n",
      "val loss =  3.4985833168029785 val score =  0.4957107843137255\n",
      "epoch 163:\n",
      "train loss =  0.013757122680544853 train score =  0.9957395764394441\n",
      "val loss =  3.857543468475342 val score =  0.49865196078431373\n",
      "epoch 164:\n",
      "train loss =  0.013757770881056786 train score =  0.9952576935804103\n",
      "val loss =  3.8784289360046387 val score =  0.4963235294117647\n",
      "epoch 165:\n",
      "train loss =  0.013613730669021606 train score =  0.9957809397749835\n",
      "val loss =  3.6436595916748047 val score =  0.492156862745098\n",
      "epoch 166:\n",
      "train loss =  0.013049707747995853 train score =  0.9961532097948379\n",
      "val loss =  3.8268091678619385 val score =  0.49926470588235294\n",
      "epoch 167:\n",
      "train loss =  0.01394712645560503 train score =  0.9957602581072138\n",
      "val loss =  3.617546558380127 val score =  0.4959558823529412\n",
      "epoch 168:\n",
      "train loss =  0.012952681630849838 train score =  0.995946393117141\n",
      "val loss =  3.8355886936187744 val score =  0.49473039215686276\n",
      "epoch 169:\n",
      "train loss =  0.014163803309202194 train score =  0.9954913964262078\n",
      "val loss =  3.5995163917541504 val score =  0.4991421568627451\n",
      "epoch 170:\n",
      "train loss =  0.012672370299696922 train score =  0.99600843812045\n",
      "val loss =  3.8786075115203857 val score =  0.5006127450980392\n",
      "epoch 171:\n",
      "train loss =  0.012256760150194168 train score =  0.9961573461283917\n",
      "val loss =  3.9928460121154785 val score =  0.5004901960784314\n",
      "epoch 172:\n",
      "train loss =  0.013577228412032127 train score =  0.9958533256121773\n",
      "val loss =  3.8403289318084717 val score =  0.49607843137254903\n",
      "epoch 173:\n",
      "train loss =  0.012056165374815464 train score =  0.9961635506287227\n",
      "val loss =  3.998746871948242 val score =  0.49411764705882355\n",
      "epoch 174:\n",
      "train loss =  0.013156276196241379 train score =  0.9958636664460622\n",
      "val loss =  3.735095262527466 val score =  0.49669117647058825\n",
      "epoch 175:\n",
      "train loss =  0.012282326817512512 train score =  0.9963083223031105\n",
      "val loss =  3.941448211669922 val score =  0.49411764705882355\n",
      "epoch 176:\n",
      "train loss =  0.013305586762726307 train score =  0.995677531436135\n",
      "val loss =  3.8640847206115723 val score =  0.4980392156862745\n",
      "epoch 177:\n",
      "train loss =  0.013389883562922478 train score =  0.9960704831237591\n",
      "val loss =  3.7189409732818604 val score =  0.49411764705882355\n",
      "epoch 178:\n",
      "train loss =  0.012256143614649773 train score =  0.9963290039708802\n",
      "val loss =  3.9710745811462402 val score =  0.4985294117647059\n",
      "epoch 179:\n",
      "train loss =  0.012723070569336414 train score =  0.9957809397749835\n",
      "val loss =  4.005402088165283 val score =  0.49669117647058825\n",
      "epoch 180:\n",
      "train loss =  0.013343552127480507 train score =  0.995677531436135\n",
      "val loss =  3.9424147605895996 val score =  0.49583333333333335\n",
      "epoch 181:\n",
      "train loss =  0.012778088450431824 train score =  0.9961221872931834\n",
      "val loss =  3.659209966659546 val score =  0.49497549019607845\n",
      "epoch 182:\n",
      "train loss =  0.013008113950490952 train score =  0.9957085539377896\n",
      "val loss =  3.551588535308838 val score =  0.5036764705882353\n",
      "epoch 183:\n",
      "train loss =  0.01113880705088377 train score =  0.996877068166777\n",
      "val loss =  4.213707447052002 val score =  0.5029411764705882\n",
      "epoch 184:\n",
      "train loss =  0.014291007071733475 train score =  0.995805757776307\n",
      "val loss =  3.613402843475342 val score =  0.49963235294117647\n",
      "epoch 185:\n",
      "train loss =  0.01196829229593277 train score =  0.9962462772998014\n",
      "val loss =  3.8092641830444336 val score =  0.49301470588235297\n",
      "epoch 186:\n",
      "train loss =  0.011268950998783112 train score =  0.9962566181336863\n",
      "val loss =  3.936053991317749 val score =  0.501593137254902\n",
      "epoch 187:\n",
      "train loss =  0.011386048048734665 train score =  0.9962876406353408\n",
      "val loss =  3.854463815689087 val score =  0.49558823529411766\n",
      "epoch 188:\n",
      "train loss =  0.012203756719827652 train score =  0.9961118464592985\n",
      "val loss =  3.911130905151367 val score =  0.5020833333333333\n",
      "epoch 189:\n",
      "train loss =  0.013376694172620773 train score =  0.9957912806088683\n",
      "val loss =  3.6682395935058594 val score =  0.49387254901960786\n",
      "epoch 190:\n",
      "train loss =  0.011516589671373367 train score =  0.9964530939774984\n",
      "val loss =  3.9541015625 val score =  0.4993872549019608\n",
      "epoch 191:\n",
      "train loss =  0.012005750089883804 train score =  0.9963290039708802\n",
      "val loss =  3.8711929321289062 val score =  0.4982843137254902\n",
      "epoch 192:\n",
      "train loss =  0.012977276928722858 train score =  0.9963083223031105\n",
      "val loss =  3.618499517440796 val score =  0.4887254901960784\n",
      "epoch 193:\n",
      "train loss =  0.012182367965579033 train score =  0.9961635506287227\n",
      "val loss =  3.61691951751709 val score =  0.49264705882352944\n",
      "epoch 194:\n",
      "train loss =  0.012214450165629387 train score =  0.9960125744540039\n",
      "val loss =  3.8096885681152344 val score =  0.49436274509803924\n",
      "epoch 195:\n",
      "train loss =  0.011978121474385262 train score =  0.9962979814692257\n",
      "val loss =  3.868734121322632 val score =  0.4954656862745098\n",
      "epoch 196:\n",
      "train loss =  0.011408575810492039 train score =  0.9965565023163467\n",
      "val loss =  3.897205352783203 val score =  0.4944852941176471\n",
      "epoch 197:\n",
      "train loss =  0.011581901460886002 train score =  0.9967116148246195\n",
      "val loss =  3.995558261871338 val score =  0.4963235294117647\n",
      "epoch 198:\n",
      "train loss =  0.01140756905078888 train score =  0.9963600264725347\n",
      "val loss =  4.028913497924805 val score =  0.49865196078431373\n",
      "epoch 199:\n",
      "train loss =  0.01249002292752266 train score =  0.9960291197882197\n",
      "val loss =  3.9180359840393066 val score =  0.4970588235294118\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epoch = 200\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func.to(device)\n",
    "pred_func = ClipPairWisePred()\n",
    "pred_func.to(device)\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for e in range(epoch):\n",
    "    print(f'epoch {e}:')\n",
    "\n",
    "    # train\n",
    "    net.train()\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in train_dataloader:\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "\n",
    "            # process model\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            output = net(torch.concat((features[0], features[1]), dim=0).unsqueeze(0).to(device))\n",
    "            loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "            PRED = get_order_list(output.reshape(-1).cpu())\n",
    "            GT = gt\n",
    "            score_shot = int(PRED == gt)\n",
    "            # print(PRED, GT)\n",
    "            loss_batch_list.append(loss_shot)\n",
    "            score_batch_list.append(score_shot)\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "        loss_step.backward()\n",
    "        optim.step()\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        wandb.log({'train loss':loss_step.item(), 'train score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('train loss = ', loss_epoch.item(), 'train score = ', score_epoch)  \n",
    "\n",
    "    # val\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_epoch_list = []\n",
    "        score_epoch_list = []\n",
    "        for batch_data in val_dataloader:\n",
    "            loss_batch_list = []\n",
    "            score_batch_list = []\n",
    "\n",
    "            for shot_data in batch_data: #clip data\n",
    "                # read input data\n",
    "                features, gt = shot_data\n",
    "\n",
    "                output = net(torch.concat((features[0], features[1]), dim=0).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[0]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_list(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "                \n",
    "            # calcuclate avearge batch\n",
    "            score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "            loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "            # caculate avearge score\n",
    "            score_epoch_list.append(score_step)\n",
    "            loss_epoch_list.append(loss_step)\n",
    "            wandb.log({'val loss':loss_step.item(), 'val score':score_step})\n",
    "\n",
    "        score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "        loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "        print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)\n",
    "        if score_epoch >= best_val_acc: \n",
    "            best_val_acc = score_epoch\n",
    "            torch.save(net.state_dict(), Path('./checkpoint', f'frame_to_shot_best_{timestamp}.pth'))\n",
    "            print(\"save epoch \",e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jianghui/dataset/VideoReorder-MovieNet/test_in_domain_shot.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_in_domain\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m test_in_data \u001b[39m=\u001b[39m VideoReorderMovieNetDataFolder(root\u001b[39m=\u001b[39;49mdata_path, split\u001b[39m=\u001b[39;49msplit, layer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mshot\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m test_in_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(test_in_data, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m(split \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m), num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x)\n\u001b[1;32m      5\u001b[0m split \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_out_domain\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/VideoReorder/utils/dataset.py:58\u001b[0m, in \u001b[0;36mVideoReorderMovieNetDataFolder.__init__\u001b[0;34m(self, root, split, layer, transform)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(Path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00msplit\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/VU_ipy/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/VU_ipy/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/VU_ipy/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jianghui/dataset/VideoReorder-MovieNet/test_in_domain_shot.pt'"
     ]
    }
   ],
   "source": [
    "split = 'test_in_domain'\n",
    "test_in_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "test_in_dataloader = torch.utils.data.DataLoader(test_in_data, batch_size=128, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)\n",
    "\n",
    "split = 'test_out_domain'\n",
    "test_out_data = VideoReorderMovieNetDataFolder(root=data_path, split=split, layer='shot')\n",
    "test_out_dataloader = torch.utils.data.DataLoader(test_out_data, batch_size=128, shuffle=(split == 'train'), num_workers=8, pin_memory=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and test val\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2)\n",
    ")\n",
    "checkpoint = torch.load(Path('./checkpoint', f'frame_to_shot_best_{timestamp}.pth'))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test val\n",
    "with torch.no_grad():\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(val_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "            \n",
    "            if len(gt) == 2:\n",
    "                output = model(features.reshape(-1).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "            elif len(gt) == 3:\n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(3):\n",
    "                    for second_frame in range(first_frame + 1, 3):\n",
    "                        output = model(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                        GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / 3)\n",
    "                score_batch_list.append(score_shot / 3)\n",
    "            else:\n",
    "                assert False, 'shot frame is neither 2 nor 3'\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        # wandb.log({'val loss':loss_step.item(), 'val score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('val loss = ', loss_epoch.item(), 'val score = ', score_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try test_in_domain\n",
    "with torch.no_grad():\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(test_in_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "            \n",
    "            if len(gt) == 2:\n",
    "                output = model(features.reshape(-1).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "            elif len(gt) == 3:\n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(3):\n",
    "                    for second_frame in range(first_frame + 1, 3):\n",
    "                        output = model(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                        GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / 3)\n",
    "                score_batch_list.append(score_shot / 3)\n",
    "            else:\n",
    "                assert False, 'shot frame is neither 2 nor 3'\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        # wandb.log({'test in domain loss':loss_step.item(), 'test_in_domain score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('test_in_domain loss = ', loss_epoch.item(), 'test_in_domain score = ', score_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out domain\n",
    "with torch.no_grad():\n",
    "    loss_epoch_list = []\n",
    "    score_epoch_list = []\n",
    "    for batch_data in tqdm(test_out_dataloader):\n",
    "        loss_batch_list = []\n",
    "        score_batch_list = []\n",
    "\n",
    "        for shot_data in batch_data: #clip data\n",
    "            # read input data\n",
    "            features, gt = shot_data\n",
    "            \n",
    "            if len(gt) == 2:\n",
    "                output = model(features.reshape(-1).unsqueeze(0).to(device))\n",
    "                loss_shot = loss_func(output, torch.tensor(gt[1]).unsqueeze(0).to(device))\n",
    "\n",
    "                PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                GT = gt\n",
    "                score_shot = int(PRED == gt)\n",
    "                # print(PRED, GT)\n",
    "                loss_batch_list.append(loss_shot)\n",
    "                score_batch_list.append(score_shot)\n",
    "            elif len(gt) == 3:\n",
    "                loss_shot = 0\n",
    "                score_shot = 0\n",
    "                for first_frame in range(3):\n",
    "                    for second_frame in range(first_frame + 1, 3):\n",
    "                        output = model(features[[first_frame, second_frame],...].reshape(-1).unsqueeze(0).to(device))\n",
    "                        loss_shot += loss_func(output, torch.tensor([1]).to(device) if gt[first_frame] < gt[second_frame] else torch.tensor([0]).to(device))\n",
    "                        PRED = get_order_index(output.reshape(-1).cpu())\n",
    "                        GT = get_order_index([gt[first_frame], gt[second_frame]])\n",
    "                        # print(PRED, GT)\n",
    "                        score_shot += int(PRED == GT)\n",
    "                        # print(score_shot)\n",
    "                loss_batch_list.append(loss_shot / 3)\n",
    "                score_batch_list.append(score_shot / 3)\n",
    "            else:\n",
    "                assert False, 'shot frame is neither 2 nor 3'\n",
    "            \n",
    "        # calcuclate avearge batch\n",
    "        score_step = sum(score_batch_list) / len(score_batch_list)\n",
    "        loss_step = sum(loss_batch_list) / len(loss_batch_list)\n",
    "\n",
    "        # caculate avearge score\n",
    "        score_epoch_list.append(score_step)\n",
    "        loss_epoch_list.append(loss_step)\n",
    "        # wandb.log({'test out domain loss':loss_step.item(), 'test out domain score':score_step})\n",
    "\n",
    "    score_epoch = sum(score_epoch_list) / len(score_epoch_list)\n",
    "    loss_epoch = sum(loss_epoch_list) / len(loss_epoch_list)\n",
    "    print('test out domain loss = ', loss_epoch.item(), 'test out domain score = ', score_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41833333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.6 + 0.24 + 1/3 + 1/2) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VU_ipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ccc6d80109d080f1019495c65bf46629c28f35c0a7d27f040aac1d408f9814c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
